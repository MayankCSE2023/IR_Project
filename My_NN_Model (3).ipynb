{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djLRFAtvyOdK",
        "outputId": "04e97270-4012-40ab-c6cb-49a98438264d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IRLIMQPiQWOO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "s1ZZgi7iUDLR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Set your dataset directory path\n",
        "dataset_dir = \"/content/drive/MyDrive/Food_Classification_India\"\n",
        "\n",
        "# Create directories for train, validation, and test sets\n",
        "train_dir = \"/content/train\"\n",
        "validation_dir = \"/content/validate\"\n",
        "test_dir = \"/content/test\"\n",
        "\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(validation_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wK5RoEc9Usuj"
      },
      "outputs": [],
      "source": [
        "# Define the split ratio\n",
        "train_split = 0.7\n",
        "val_split = 0.15\n",
        "test_split = 0.15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xUqwDM6Uwlb",
        "outputId": "50cabf8c-cc58-4f9b-bc53-86fd493290e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset split complete.\n"
          ]
        }
      ],
      "source": [
        "# Iterate through each folder in the dataset\n",
        "for folder_name in os.listdir(dataset_dir):\n",
        "    folder_path = os.path.join(dataset_dir, folder_name)\n",
        "\n",
        "    # Get list of images in the folder\n",
        "    images = os.listdir(folder_path)\n",
        "    random.shuffle(images)  # Shuffle images\n",
        "\n",
        "    # Calculate split sizes\n",
        "    num_images = len(images)\n",
        "    num_train = int(num_images * train_split)\n",
        "    num_val = int(num_images * val_split)\n",
        "    num_test = num_images - num_train - num_val\n",
        "\n",
        "    # Split images\n",
        "    train_images = images[:num_train]\n",
        "    val_images = images[num_train:num_train + num_val]\n",
        "    test_images = images[num_train + num_val:]\n",
        "\n",
        "    # Move images to respective directories\n",
        "    for img in train_images:\n",
        "        src = os.path.join(folder_path, img)\n",
        "        dst = os.path.join(train_dir, folder_name)\n",
        "        os.makedirs(dst, exist_ok=True)\n",
        "        shutil.copy(src, dst)\n",
        "\n",
        "    for img in val_images:\n",
        "        src = os.path.join(folder_path, img)\n",
        "        dst = os.path.join(validation_dir, folder_name)\n",
        "        os.makedirs(dst, exist_ok=True)\n",
        "        shutil.copy(src, dst)\n",
        "\n",
        "    for img in test_images:\n",
        "        src = os.path.join(folder_path, img)\n",
        "        dst = os.path.join(test_dir, folder_name)\n",
        "        os.makedirs(dst, exist_ok=True)\n",
        "        shutil.copy(src, dst)\n",
        "\n",
        "print(\"Dataset split complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8sLuIdkQcIP",
        "outputId": "a06a4646-0270-40d3-af01-612425448924"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2751 files belonging to 20 classes.\n",
            "Found 588 files belonging to 20 classes.\n",
            "Found 590 files belonging to 20 classes.\n"
          ]
        }
      ],
      "source": [
        "img_height, img_width = 224, 224\n",
        "batch_size = 10\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"train\",\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"validate\",\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size\n",
        ")\n",
        "\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"test\",\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FbO6-bqGR077"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "     tf.keras.layers.Rescaling(1./255),\n",
        "     tf.keras.layers.Conv2D(32, 3, activation=\"relu\"),\n",
        "     tf.keras.layers.MaxPooling2D(),\n",
        "     tf.keras.layers.Conv2D(32, 3, activation=\"relu\"),\n",
        "     tf.keras.layers.MaxPooling2D(),\n",
        "     tf.keras.layers.Conv2D(32, 3, activation=\"relu\"),\n",
        "     tf.keras.layers.MaxPooling2D(),\n",
        "     tf.keras.layers.Flatten(),\n",
        "     tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "     tf.keras.layers.Dense(56, activation=\"softmax\")  # Adjusted for 20 classes\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Bt8Dg5FkSaYk"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=tf.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tX_sRihnSh4f",
        "outputId": "a184cb35-44b2-4e61-e510-5699e825a842"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5727: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "276/276 [==============================] - 233s 835ms/step - loss: 2.8743 - accuracy: 0.1170 - val_loss: 2.6550 - val_accuracy: 0.1497\n",
            "Epoch 2/5\n",
            "276/276 [==============================] - 220s 797ms/step - loss: 2.3902 - accuracy: 0.2563 - val_loss: 2.5876 - val_accuracy: 0.1973\n",
            "Epoch 3/5\n",
            "276/276 [==============================] - 219s 792ms/step - loss: 1.8323 - accuracy: 0.4329 - val_loss: 2.7700 - val_accuracy: 0.2534\n",
            "Epoch 4/5\n",
            "276/276 [==============================] - 226s 817ms/step - loss: 1.0360 - accuracy: 0.6685 - val_loss: 3.4788 - val_accuracy: 0.2551\n",
            "Epoch 5/5\n",
            "276/276 [==============================] - 223s 807ms/step - loss: 0.4507 - accuracy: 0.8684 - val_loss: 4.5275 - val_accuracy: 0.2296\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7887ac7c0b20>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "model.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs = 5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BF0FiK6ZZC3u",
        "outputId": "200628a0-b140-4a6d-b473-6e74a77901f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "276/276 [==============================] - 88s 313ms/step - loss: 0.3025 - accuracy: 0.9062\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.30245086550712585, 0.9062159061431885]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model.evaluate(train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bo4k1NnIYoxn",
        "outputId": "e2b34539-62a4-4bac-fd9c-3d0d0b5e6830"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['burger', 'butter_naan', 'chai', 'chapati', 'chole_bhature', 'dal_makhani', 'dhokla', 'fried_rice', 'idli', 'jalebi', 'kaathi_rolls', 'kadai_paneer', 'kulfi', 'masala_dosa', 'momos', 'paani_puri', 'pakode', 'pav_bhaji', 'pizza', 'samosa']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Get the class names from the folder names in the train directory\n",
        "class_names = sorted(os.listdir(train_dir))\n",
        "\n",
        "# Print the class names to verify\n",
        "print(class_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mwARqVPPdJtZ"
      },
      "outputs": [],
      "source": [
        "# Resize images to the correct input shape\n",
        "train_ds = train_ds.map(lambda x, y: (tf.image.resize(x, (224, 224)), y))\n",
        "val_ds = val_ds.map(lambda x, y: (tf.image.resize(x, (224, 224)), y))\n",
        "test_ds = test_ds.map(lambda x, y: (tf.image.resize(x, (224, 224)), y))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KaiptXTTY20p",
        "outputId": "dba27727-1d16-4bdd-dd62-d524cb7ab47b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load pre-trained VGG16 model without the top dense layers\n",
        "base_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "EzG7lTXSbDVP"
      },
      "outputs": [],
      "source": [
        "# Freeze the pre-trained layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add new dense layers on top of the pre-trained model\n",
        "validate_synchronization_aggregation_trainablemodel = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(len(class_names), activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "FkNNpccSbUGa"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "validate_synchronization_aggregation_trainablemodel.compile(optimizer='adam',\n",
        "                                                           loss='sparse_categorical_crossentropy',\n",
        "                                                           metrics=['accuracy'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgdyaNfHboW6",
        "outputId": "f9b13bdb-62e1-4eae-d8f2-853320836586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "276/276 [==============================] - 1859s 7s/step - loss: 3.9506 - accuracy: 0.2196 - val_loss: 2.1282 - val_accuracy: 0.3673\n",
            "Epoch 2/5\n",
            "276/276 [==============================] - 1844s 7s/step - loss: 2.1280 - accuracy: 0.3828 - val_loss: 1.7397 - val_accuracy: 0.4779\n",
            "Epoch 3/5\n",
            "276/276 [==============================] - 1893s 7s/step - loss: 1.7579 - accuracy: 0.4875 - val_loss: 1.4798 - val_accuracy: 0.5595\n",
            "Epoch 4/5\n",
            "276/276 [==============================] - 1832s 7s/step - loss: 1.4361 - accuracy: 0.5678 - val_loss: 1.3998 - val_accuracy: 0.6054\n",
            "Epoch 5/5\n",
            "276/276 [==============================] - 1822s 7s/step - loss: 1.3285 - accuracy: 0.5932 - val_loss: 1.3209 - val_accuracy: 0.6259\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = validate_synchronization_aggregation_trainablemodel.fit(train_ds,\n",
        "                                                                  validation_data=val_ds,\n",
        "                                                                  epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ahRpAys7b9Bd"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test dataset\n",
        "test_loss, test_accuracy = validate_synchronization_aggregation_trainablemodel.evaluate(test_ds)\n",
        "\n",
        "# Print the test accuracy\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeCrw5AAFI1g",
        "outputId": "b3b30afc-bb66-4087-94b3-f3b8175a4cff"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59/59 [==============================] - 330s 5s/step - loss: 1.2409 - accuracy: 0.6288\n",
            "Test Accuracy: 0.6288135647773743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ub5n_wUMgrDw"
      },
      "outputs": [],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(validate_synchronization_aggregation_trainablemodel)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open(\"model.tflite\", 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}